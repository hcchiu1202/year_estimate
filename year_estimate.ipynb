{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "#from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'train_images'\n",
    "\n",
    "time_run = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir = 'results/' + time_run\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "transform_mean = transform_std = np.array([None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_images\\train_0001.png</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_images\\train_0002.png</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_images\\train_0003.png</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_images\\train_0004.png</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_images\\train_0005.png</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_path  label\n",
       "0  train_images\\train_0001.png   2012\n",
       "1  train_images\\train_0002.png   2003\n",
       "2  train_images\\train_0003.png   1994\n",
       "3  train_images\\train_0004.png   2014\n",
       "4  train_images\\train_0005.png   2003"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_labels.csv\", names=[\"name\", \"label\"], header=None)\n",
    "df[\"image_path\"] = df[\"name\"].apply(lambda x: os.path.join(data_dir, x))\n",
    "df = df[[\"image_path\", \"label\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_images\\\\train_0001.png'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"image_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 16\n",
    "image_size = 256\n",
    "input_size = 224\n",
    "n_classes = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transform_mean.any() == None:\n",
    "    transform_mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "if transform_std.any() == None:\n",
    "    transform_std = np.array([0.2470, 0.2435, 0.2616])\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, data_dir, augment=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        if augment:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.RandomCrop(128, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=transform_mean, std=transform_std)\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=transform_mean, std=transform_std)\n",
    "            ])\n",
    "\n",
    "        self.labels = df[\"label\"]\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = df[\"image_path\"][idx]\n",
    "        image = Image.open(img_name).convert(\"RGB\")   \n",
    "        image = self.transform(image)\n",
    "        \n",
    "        label = df[\"label\"][idx] - 1979\n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "                    df, test_size=0.2, random_state=42, shuffle=True, stratify=df[\"label\"]\n",
    "                    )\n",
    "    \n",
    "    \n",
    "\n",
    "train_dataset = ImageDataset(train_df, data_dir, augment=True)\n",
    "val_dataset = ImageDataset(val_df, data_dir, augment=False)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=0,\n",
    "#                                           pin_memory=True,\n",
    "                                           drop_last=True\n",
    "                                          )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False, \n",
    "                                           num_workers=0,\n",
    "#                                           pin_memory=True,\n",
    "                                           drop_last=False\n",
    "                                         )\n",
    "\n",
    "train_dataset_size = len(train_dataset)\n",
    "val_dataset_size = len(val_dataset)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "try writing from scratch the Shake-Shake regularization (Gastaldi, 2017), SOTA error rate 2.86%\n",
    "partly referred to https://github.com/hysts/pytorch_shake_shake when I had no idea\n",
    "I did not implement all the features mentioned in the paper, \n",
    "but I consider I have included most juice out of it.\n",
    "\"\"\"\n",
    "######################## This part function not verified ###################\n",
    "def initialize_weights(module):\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(module.weight.data, mode='fan_out')\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        module.weight.data.fill_(1)\n",
    "        module.bias.data.zero_()\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        module.bias.data.zero_()\n",
    "############################################################################\n",
    "\n",
    "class ResPath(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, stride):\n",
    "        super(ResPath, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, out_chan, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_chan)\n",
    "        self.conv2 = nn.Conv2d(out_chan, out_chan, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_chan)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(F.relu(x, inplace=False)))\n",
    "        x = self.bn2(self.conv2(F.relu(x, inplace=False)))\n",
    "        return x\n",
    "\n",
    "class DownSamplePath(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan):\n",
    "        super(DownSamplePath, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chan, in_chan, 1, 1, 0, bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_chan, in_chan, 1, 1, 0, bias=False) # although identical, but still need to separate otherwise parameters will be mixed? NEED VERIFY\n",
    "        self.bn1 = nn.BatchNorm2d(out_chan)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(x, inplace=False)\n",
    "        \n",
    "        x1 = F.avg_pool2d(x, 1, stride=2, padding=0)\n",
    "        x1 = self.conv1(x1)\n",
    "        \n",
    "        x2 = F.pad(x[:, :, 1:, 1:], (0, 1, 0, 1))   # not familiar with this\n",
    "        x2 = F.avg_pool2d(x2, 1, stride=2, padding=0)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        y = torch.cat([x1, x2], dim=1)\n",
    "        y = self.bn1(y)\n",
    "        return y\n",
    "    \n",
    "class ShakeFunc(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x1, x2, alpha, beta):\n",
    "        ctx.save_for_backward(x1, x2, alpha, beta)\n",
    "        y = x1 * alpha + x2 * (1 - alpha)\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x1, x2, alpha, beta = ctx.saved_tensors\n",
    "        grad_x1 = grad_x2 = grad_alpha = grad_beta = None\n",
    "        grad_x1 = grad_output * beta\n",
    "        grad_x2 = grad_output * (1 - beta)\n",
    "        \"\"\" For better efficiency, use instead:\n",
    "        if ctx.needs_input_grad[0]:  \n",
    "            grad_x1 = grad_output * beta\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_x2 = grad_output * (1 - beta)\n",
    "        \"\"\"\n",
    "        return grad_x1, grad_x2, grad_alpha, grad_beta\n",
    "ShakeFunc = ShakeFunc.apply\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, stride):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.path1 = ResPath(in_chan, out_chan, stride)\n",
    "        self.path2 = ResPath(in_chan, out_chan, stride)\n",
    "        \n",
    "        self.down_sample = nn.Sequential()\n",
    "        if in_chan != out_chan:\n",
    "            self.down_sample.add_module(\"DownSamplePath\", DownSamplePath(in_chan, out_chan))\n",
    "        \n",
    "    def get_alpha_beta(self, batch_size, is_training, device):\n",
    "        \"\"\"only Shake-Shake-Image is implemented here\"\"\"\n",
    "        if is_training:\n",
    "            alpha = torch.rand((batch_size, 1, 1, 1))\n",
    "            beta = torch.rand((batch_size, 1, 1, 1))\n",
    "        else:\n",
    "            alpha = torch.ones((batch_size, 1, 1, 1)) * 0.5\n",
    "            beta = torch.ones((batch_size, 1, 1, 1)) * 0.5 \n",
    "            #alpha = torch.FloatTensor([0.5])\n",
    "            #beta = torch.FloatTensor([0.5])\n",
    "        alpha = alpha.to(device)\n",
    "        beta = beta.to(device)\n",
    "        return alpha, beta\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.path1(x)\n",
    "        x2 = self.path2(x)\n",
    "#        is_training = True if model.train() else False\n",
    "        alpha, beta = self.get_alpha_beta(x.size(0), self.training, x.device)\n",
    "        y = ShakeFunc(x1, x2, alpha, beta)\n",
    "        return self.down_sample(x) + y    \n",
    "    \n",
    "class ResStage(nn.Module):\n",
    "    \"\"\"Might be a bit redundant to define a new class for this? I made this class just for clarity\"\"\"\n",
    "    def __init__(self, in_chan, out_chan, stride, n_blocks=4):\n",
    "        super(ResStage, self).__init__()\n",
    "        self.stage = nn.Sequential()\n",
    "        for idx in range(n_blocks):\n",
    "            if idx == 0:\n",
    "                self.stage.add_module(\"block{}\".format(idx+1), ResBlock(in_chan, out_chan, stride=stride))\n",
    "            else:\n",
    "                self.stage.add_module(\"block{}\".format(idx+1), ResBlock(out_chan, out_chan, stride=1))      \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage(x) # this looks a bit stupid...\n",
    "        return x\n",
    "    \n",
    "class Shakeshake(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, n_channels[0], 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels[0])\n",
    "        self.stage1 = ResStage(n_channels[0], n_channels[0], stride=1)\n",
    "        self.stage2 = ResStage(n_channels[0], n_channels[1], stride=2)\n",
    "        self.stage3 = ResStage(n_channels[1], n_channels[2], stride=2)\n",
    "        self.fc1 = nn.Linear(n_channels[2], n_classes)\n",
    "    \n",
    "        # initialize weights\n",
    "        self.apply(initialize_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_chan = 32\n",
    "n_channels = [base_chan, base_chan * 2, base_chan * 4]\n",
    "\n",
    "#model = Network()\n",
    "model = Shakeshake(n_channels, n_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=9, gamma=0.33)\n",
    "\n",
    "T_max = n_epoch * train_dataset_size\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1)\n",
    "\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## auxilliary functions\n",
    "\n",
    "def get_config():\n",
    "    config = OrderedDict({'name':time_run,\n",
    "                          'nepoch':n_epoch,\n",
    "                          'base_chan':base_chan,\n",
    "                          'loss_func':str(loss_func),\n",
    "                          'optimizer':str(optimizer),\n",
    "                          'scheduler':str(scheduler.__dict__),\n",
    "                          'model':str(model),\n",
    "                          'train_loader':str(train_loader.__dict__), \n",
    "                          'val_loader':str(val_loader.__dict__)})\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_func, train_loader, optimizer, scheduler, writer):\n",
    "    global global_step\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0            \n",
    "    running_correct = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        global_step +=1\n",
    "        inputs, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "#        if i == 0:\n",
    "#            image = torchvision.utils.make_grid(\n",
    "#                inputs, normalize=True, scale_each=True)\n",
    "#            writer.add_image('Train/Image', image, epoch)\n",
    "        \n",
    "        scheduler.step()        \n",
    "        \n",
    "        writer.add_scalar('Train/LearningRate',\n",
    "                            scheduler.get_lr()[0], global_step)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_correct += np.double(torch.sum(predicted == labels.data))\n",
    "        \n",
    "        writer.add_scalar('Train/RunningLoss', running_loss , global_step)\n",
    "        writer.add_scalar('Train/RunningAccuracy', running_correct , global_step)\n",
    "        \n",
    "    train_loss = running_loss / train_dataset_size\n",
    "    train_acc = running_correct / train_dataset_size\n",
    "\n",
    "    elapsed = time.time() - since\n",
    "    \n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Train/Accuracy', train_acc, epoch)\n",
    "    writer.add_scalar('Train/Time', elapsed, epoch)\n",
    "\n",
    "    train_log = OrderedDict({\n",
    "    'epoch':\n",
    "    epoch,\n",
    "    'train':\n",
    "    OrderedDict({\n",
    "        'loss': train_loss,\n",
    "        'accuracy': train_acc,\n",
    "        'time': elapsed,\n",
    "        }),\n",
    "    })\n",
    "      \n",
    "    print('Train Loss:{:.6f} Accuracy:{:.4f} \\nTime:{:.1f}s'.format(train_loss, train_acc, elapsed))        \n",
    "        \n",
    "    return train_log, train_acc\n",
    "\n",
    "def val(epoch, model, loss_func, val_loader, writer):\n",
    "    global global_step\n",
    "    since = time.time()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0            \n",
    "    running_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            global_step +=1\n",
    "            inputs, labels = data[\"image\"], data[\"label\"]\n",
    "            \n",
    "#            if i == 0:\n",
    "#                image = torchvision.utils.make_grid(\n",
    "#                    inputs, normalize=True, scale_each=True)\n",
    "#                writer.add_image('Test/Image', image, epoch)\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_correct += np.double(torch.sum(predicted == labels.data))\n",
    "    val_loss = running_loss / val_dataset_size\n",
    "    val_acc = running_correct / val_dataset_size\n",
    "\n",
    "    elapsed = time.time() - since\n",
    "\n",
    "    if epoch > 0:\n",
    "        writer.add_scalar('Val/Loss', val_loss, epoch)\n",
    "    writer.add_scalar('Val/Accuracy', val_acc, epoch)\n",
    "    writer.add_scalar('Val/Time', elapsed, epoch)    \n",
    "    \n",
    "    val_log = OrderedDict({\n",
    "    'epoch':\n",
    "    epoch,\n",
    "    'val':\n",
    "    OrderedDict({\n",
    "        'loss': val_loss,\n",
    "        'accuracy':val_acc,\n",
    "        'time': elapsed,\n",
    "        }),\n",
    "    })\n",
    "    \n",
    "    print('Val Loss:{:.6f} Accuracy:{:.4f} \\nTime:{:.1f}s'.format(val_loss, val_acc, elapsed))  \n",
    "    \n",
    "    return val_log, val_acc\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(time_run)\n",
    "    \n",
    "    config = get_config()\n",
    "    with open(save_dir+'/{}_config.json'.format(time_run), 'w') as fout:\n",
    "        json.dump(config, fout, indent=2)\n",
    "        \n",
    "#    summary(model, (3, 32, 32))\n",
    "#    print('no. epoch:', nepoch, \"batch size:\", BATCH_SIZE, \"optimizer:\", optimizer)\n",
    "    train_since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "######################## This part function not verified ###################    \n",
    "    # set random seed\n",
    "    seed = 17 # arbitrary\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "###########################################################################    \n",
    "    writer = SummaryWriter(save_dir)\n",
    "    \n",
    "    # run test before start training? whats that??????????\n",
    "    val(0, model, loss_func, val_loader, writer)\n",
    "    \n",
    "    epoch_logs = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, n_epoch - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_log, train_acc = train(epoch, model, loss_func, train_loader, optimizer, scheduler, writer)\n",
    "        val_log, val_acc = val(epoch, model, loss_func, val_loader, writer)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "\n",
    "        print()\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        epoch_log = train_log.copy()\n",
    "        epoch_log.update(val_log)\n",
    "        epoch_logs.append(epoch_log)\n",
    "        with open(save_dir+'/{}_log.json'.format(time_run), 'w') as fout:\n",
    "            json.dump(epoch_logs, fout, indent=2)\n",
    "        \n",
    "        if epoch % 50 == 0 and epoch !=0:\n",
    "            torch.save(model.state_dict(), save_dir+'/{}_ep{}_acc{:.4f}.pth'.format(time_run, epoch, val_acc))\n",
    "    \n",
    "    accuracies = {'train_accuracy':np.array(train_accs), 'val_accuracy':np.array(val_accs)}\n",
    "    np.save(save_dir+'/{}_accs.npy'.format(time_run), accuracies)\n",
    "    \n",
    "    train_elapsed = time.time() - train_since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(train_elapsed // 60, train_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), save_dir+'/{}_bestacc{:.4f}.pth'.format(time_run, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20191228_215408\n",
      "Val Loss:0.604396 Accuracy:0.0149 \n",
      "Time:15.3s\n",
      "Epoch 0/9\n",
      "----------\n",
      "Train Loss:0.297156 Accuracy:0.0555 \n",
      "Time:75.3s\n",
      "Val Loss:0.218177 Accuracy:0.0583 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "Train Loss:0.219833 Accuracy:0.0582 \n",
      "Time:75.9s\n",
      "Val Loss:0.215056 Accuracy:0.0740 \n",
      "Time:15.5s\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "Train Loss:0.216995 Accuracy:0.0763 \n",
      "Time:75.1s\n",
      "Val Loss:0.211241 Accuracy:0.0852 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "Train Loss:0.215322 Accuracy:0.0776 \n",
      "Time:75.7s\n",
      "Val Loss:0.208127 Accuracy:0.0897 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "Train Loss:0.213207 Accuracy:0.0836 \n",
      "Time:75.5s\n",
      "Val Loss:0.209501 Accuracy:0.0919 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "Train Loss:0.212324 Accuracy:0.0869 \n",
      "Time:75.5s\n",
      "Val Loss:0.204070 Accuracy:0.1181 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "Train Loss:0.211274 Accuracy:0.0883 \n",
      "Time:75.3s\n",
      "Val Loss:0.202441 Accuracy:0.1151 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "Train Loss:0.211023 Accuracy:0.0864 \n",
      "Time:75.3s\n",
      "Val Loss:0.202221 Accuracy:0.1076 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "Train Loss:0.209017 Accuracy:0.0894 \n",
      "Time:75.2s\n",
      "Val Loss:0.200740 Accuracy:0.1166 \n",
      "Time:15.3s\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "Train Loss:0.208943 Accuracy:0.0873 \n",
      "Time:75.4s\n",
      "Val Loss:0.198902 Accuracy:0.1278 \n",
      "Time:15.3s\n",
      "\n",
      "Training complete in 15m 23s\n",
      "Best val Acc: 0.1278\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
