{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "#from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'train_images'\n",
    "\n",
    "time_run = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_dir = 'results/' + time_run\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "transform_mean = transform_std = np.array([None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_images\\train_0001.png</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_images\\train_0002.png</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_images\\train_0003.png</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_images\\train_0004.png</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_images\\train_0005.png</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_path  label\n",
       "0  train_images\\train_0001.png   2012\n",
       "1  train_images\\train_0002.png   2003\n",
       "2  train_images\\train_0003.png   1994\n",
       "3  train_images\\train_0004.png   2014\n",
       "4  train_images\\train_0005.png   2003"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_labels.csv\", names=[\"name\", \"label\"], header=None)\n",
    "df[\"image_path\"] = df[\"name\"].apply(lambda x: os.path.join(data_dir, x))\n",
    "df = df[[\"image_path\", \"label\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_images\\\\train_0001.png'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"image_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 40\n",
    "batch_size = 16\n",
    "image_size = 256\n",
    "input_size = 224\n",
    "n_classes = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transform_mean.any() == None:\n",
    "    transform_mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "if transform_std.any() == None:\n",
    "    transform_std = np.array([0.2470, 0.2435, 0.2616])\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, data_dir, augment=True):\n",
    "        \n",
    "        if augment:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.RandomCrop(128, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=transform_mean, std=transform_std)\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=transform_mean, std=transform_std)\n",
    "            ])\n",
    "\n",
    "        self.labels = df[\"label\"]\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = df[\"image_path\"][idx]\n",
    "        image = Image.open(img_name).convert(\"RGB\")   \n",
    "        image = self.transform(image)\n",
    "        \n",
    "        label = df[\"label\"][idx] - 1979\n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "                    df, test_size=0.2, random_state=42, shuffle=True, stratify=df[\"label\"]\n",
    "                    )    \n",
    "\n",
    "train_dataset = ImageDataset(train_df, data_dir, augment=True)\n",
    "val_dataset = ImageDataset(val_df, data_dir, augment=False)\n",
    "\n",
    "train_df.to_csv(\"results/list_train.csv\", header=None, index=None)\n",
    "val_df.to_csv(\"results/list_val.csv\", header=None, index=None)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=0,\n",
    "#                                           pin_memory=True,\n",
    "                                           drop_last=True\n",
    "                                          )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False, \n",
    "                                           num_workers=0,\n",
    "#                                           pin_memory=True,\n",
    "                                           drop_last=False\n",
    "                                         )\n",
    "\n",
    "train_dataset_size = len(train_dataset)\n",
    "val_dataset_size = len(val_dataset)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet = nn.Sequential(*(list(resnet.children())[:-1]))\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = False\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(2048, n_classes)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        out = F.softmax(self.fc(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet(n_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4, nesterov=True)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=9, gamma=0.33)\n",
    "\n",
    "#T_max = n_epoch * train_dataset_size\n",
    "#scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1)\n",
    "\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_func, train_loader, optimizer, writer, scheduler=None):\n",
    "    global global_step\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0            \n",
    "    running_correct = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        global_step +=1\n",
    "        inputs, labels = data[\"image\"], data[\"label\"]\n",
    "  \n",
    "        scheduler.step()   \n",
    "        writer.add_scalar('Train/LearningRate',\n",
    "                            scheduler.get_lr()[0], global_step)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_correct += np.double(torch.sum(predicted == labels.data))\n",
    "    train_loss = running_loss / train_dataset_size\n",
    "    train_acc = running_correct / train_dataset_size\n",
    "\n",
    "    elapsed = time.time() - since\n",
    "    \n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Train/Accuracy', train_acc, epoch)\n",
    "    writer.add_scalar('Train/Time', elapsed, epoch)\n",
    "\n",
    "    train_log = OrderedDict({\n",
    "    'epoch':\n",
    "    epoch,\n",
    "    'train':\n",
    "    OrderedDict({\n",
    "        'loss': train_loss,\n",
    "        'accuracy': train_acc,\n",
    "        'time': elapsed,\n",
    "        }),\n",
    "    })\n",
    "      \n",
    "    print('Train Loss:{:.6f} Accuracy:{:.4f} Time:{:.1f}s'.format(train_loss, train_acc, elapsed))        \n",
    "        \n",
    "    return train_log, train_acc\n",
    "\n",
    "def val(epoch, model, loss_func, val_loader, writer):\n",
    "    global global_step\n",
    "    since = time.time()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0            \n",
    "    running_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            global_step +=1\n",
    "            inputs, labels = data[\"image\"], data[\"label\"]\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_correct += np.double(torch.sum(predicted == labels.data))\n",
    "    val_loss = running_loss / val_dataset_size\n",
    "    val_acc = running_correct / val_dataset_size\n",
    "\n",
    "    elapsed = time.time() - since\n",
    "\n",
    "    if epoch > 0:\n",
    "        writer.add_scalar('Val/Loss', val_loss, epoch)\n",
    "        writer.add_scalar('Val/Accuracy', val_acc, epoch)\n",
    "        writer.add_scalar('Val/Time', elapsed, epoch)    \n",
    "    \n",
    "    val_log = OrderedDict({\n",
    "    'epoch':\n",
    "    epoch,\n",
    "    'val':\n",
    "    OrderedDict({\n",
    "        'loss': val_loss,\n",
    "        'accuracy':val_acc,\n",
    "        'time': elapsed,\n",
    "        }),\n",
    "    })\n",
    "    \n",
    "    print('Val Loss:{:.6f} Accuracy:{:.4f} Time:{:.1f}s'.format(val_loss, val_acc, elapsed))  \n",
    "    \n",
    "    return val_log, val_acc\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(time_run)\n",
    "    train_since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "######################## This part function not verified ###################    \n",
    "    # set random seed\n",
    "    seed = 17 # arbitrary\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "###########################################################################    \n",
    "    writer = SummaryWriter(save_dir)\n",
    "    \n",
    "    # run test before start training? whats that??????????\n",
    "    val(0, model, loss_func, val_loader, writer)\n",
    "    print()\n",
    "    epoch_logs = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch, n_epoch - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_log, train_acc = train(epoch, model, loss_func, train_loader, optimizer, writer, scheduler)\n",
    "        val_log, val_acc = val(epoch, model, loss_func, val_loader, writer)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "\n",
    "        print()\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        epoch_log = train_log.copy()\n",
    "        epoch_log.update(val_log)\n",
    "        epoch_logs.append(epoch_log)\n",
    "        with open(save_dir+'/{}_log.json'.format(time_run), 'w') as fout:\n",
    "            json.dump(epoch_logs, fout, indent=2)\n",
    "        \n",
    "        if epoch % 50 == 0 and epoch !=0:\n",
    "            torch.save(model.state_dict(), save_dir+'/{}_ep{}_acc{:.4f}.pth'.format(time_run, epoch, val_acc))\n",
    "    \n",
    "    accuracies = {'train_accuracy':np.array(train_accs), 'val_accuracy':np.array(val_accs)}\n",
    "    np.save(save_dir+'/{}_accs.npy'.format(time_run), accuracies)\n",
    "    \n",
    "    train_elapsed = time.time() - train_since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(train_elapsed // 60, train_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), save_dir+'/{}_bestacc{:.4f}.pth'.format(time_run, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20191229_001436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss:0.231598 Accuracy:0.0194 \n",
      "Time:7.4s\n",
      "Epoch 0/39\n",
      "----------\n",
      "Train Loss:0.227660 Accuracy:0.0849 \n",
      "Time:47.0s\n",
      "Val Loss:0.226508 Accuracy:0.1166 \n",
      "Time:7.4s\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "Train Loss:0.226276 Accuracy:0.1019 \n",
      "Time:47.9s\n",
      "Val Loss:0.225932 Accuracy:0.1293 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "Train Loss:0.226121 Accuracy:0.1066 \n",
      "Time:47.4s\n",
      "Val Loss:0.226366 Accuracy:0.1248 \n",
      "Time:7.4s\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "Train Loss:0.226321 Accuracy:0.1053 \n",
      "Time:47.0s\n",
      "Val Loss:0.225646 Accuracy:0.1368 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "Train Loss:0.225986 Accuracy:0.1105 \n",
      "Time:46.5s\n",
      "Val Loss:0.226684 Accuracy:0.1188 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "Train Loss:0.225993 Accuracy:0.1103 \n",
      "Time:46.3s\n",
      "Val Loss:0.226738 Accuracy:0.1203 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "Train Loss:0.226014 Accuracy:0.1096 \n",
      "Time:46.8s\n",
      "Val Loss:0.226728 Accuracy:0.1151 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "Train Loss:0.225560 Accuracy:0.1167 \n",
      "Time:46.6s\n",
      "Val Loss:0.225518 Accuracy:0.1405 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "Train Loss:0.225429 Accuracy:0.1187 \n",
      "Time:47.1s\n",
      "Val Loss:0.227613 Accuracy:0.1001 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "Train Loss:0.225768 Accuracy:0.1144 \n",
      "Time:46.8s\n",
      "Val Loss:0.225466 Accuracy:0.1398 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "Train Loss:0.225670 Accuracy:0.1159 \n",
      "Time:47.1s\n",
      "Val Loss:0.225094 Accuracy:0.1472 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "Train Loss:0.225226 Accuracy:0.1232 \n",
      "Time:48.1s\n",
      "Val Loss:0.224620 Accuracy:0.1532 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "Train Loss:0.225278 Accuracy:0.1225 \n",
      "Time:46.7s\n",
      "Val Loss:0.224932 Accuracy:0.1457 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "Train Loss:0.225331 Accuracy:0.1212 \n",
      "Time:46.2s\n",
      "Val Loss:0.225800 Accuracy:0.1308 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "Train Loss:0.224980 Accuracy:0.1275 \n",
      "Time:47.4s\n",
      "Val Loss:0.225700 Accuracy:0.1353 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "Train Loss:0.225205 Accuracy:0.1225 \n",
      "Time:46.8s\n",
      "Val Loss:0.224197 Accuracy:0.1607 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "Train Loss:0.225135 Accuracy:0.1243 \n",
      "Time:47.7s\n",
      "Val Loss:0.224606 Accuracy:0.1525 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "Train Loss:0.225230 Accuracy:0.1234 \n",
      "Time:48.0s\n",
      "Val Loss:0.224354 Accuracy:0.1622 \n",
      "Time:7.5s\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "Train Loss:0.225329 Accuracy:0.1206 \n",
      "Time:47.7s\n",
      "Val Loss:0.224490 Accuracy:0.1540 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "Train Loss:0.225168 Accuracy:0.1238 \n",
      "Time:46.8s\n",
      "Val Loss:0.223429 Accuracy:0.1749 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "Train Loss:0.225292 Accuracy:0.1217 \n",
      "Time:47.6s\n",
      "Val Loss:0.223883 Accuracy:0.1667 \n",
      "Time:7.4s\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "Train Loss:0.225206 Accuracy:0.1251 \n",
      "Time:46.5s\n",
      "Val Loss:0.224572 Accuracy:0.1487 \n",
      "Time:7.6s\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "Train Loss:0.224848 Accuracy:0.1285 \n",
      "Time:48.1s\n",
      "Val Loss:0.223433 Accuracy:0.1756 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "Train Loss:0.224871 Accuracy:0.1281 \n",
      "Time:47.1s\n",
      "Val Loss:0.224297 Accuracy:0.1592 \n",
      "Time:7.4s\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "Train Loss:0.224932 Accuracy:0.1273 \n",
      "Time:47.1s\n",
      "Val Loss:0.224660 Accuracy:0.1532 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "Train Loss:0.224884 Accuracy:0.1292 \n",
      "Time:47.4s\n",
      "Val Loss:0.224032 Accuracy:0.1682 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "Train Loss:0.224959 Accuracy:0.1279 \n",
      "Time:46.9s\n",
      "Val Loss:0.224980 Accuracy:0.1532 \n",
      "Time:7.2s\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "Train Loss:0.224448 Accuracy:0.1352 \n",
      "Time:47.6s\n",
      "Val Loss:0.223891 Accuracy:0.1674 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "Train Loss:0.224809 Accuracy:0.1296 \n",
      "Time:47.8s\n",
      "Val Loss:0.223775 Accuracy:0.1719 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "Train Loss:0.224498 Accuracy:0.1350 \n",
      "Time:46.6s\n",
      "Val Loss:0.222965 Accuracy:0.1861 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "Train Loss:0.224449 Accuracy:0.1374 \n",
      "Time:46.3s\n",
      "Val Loss:0.223607 Accuracy:0.1682 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "Train Loss:0.224306 Accuracy:0.1376 \n",
      "Time:46.7s\n",
      "Val Loss:0.223062 Accuracy:0.1756 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "Train Loss:0.224533 Accuracy:0.1348 \n",
      "Time:47.1s\n",
      "Val Loss:0.223948 Accuracy:0.1637 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "Train Loss:0.224674 Accuracy:0.1324 \n",
      "Time:47.4s\n",
      "Val Loss:0.223247 Accuracy:0.1764 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "Train Loss:0.224027 Accuracy:0.1421 \n",
      "Time:46.9s\n",
      "Val Loss:0.223115 Accuracy:0.1794 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "Train Loss:0.223986 Accuracy:0.1427 \n",
      "Time:47.1s\n",
      "Val Loss:0.223327 Accuracy:0.1764 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "Train Loss:0.224239 Accuracy:0.1384 \n",
      "Time:46.4s\n",
      "Val Loss:0.224627 Accuracy:0.1570 \n",
      "Time:7.4s\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n",
      "Train Loss:0.224899 Accuracy:0.1305 \n",
      "Time:47.4s\n",
      "Val Loss:0.223841 Accuracy:0.1674 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 38/39\n",
      "----------\n",
      "Train Loss:0.224127 Accuracy:0.1395 \n",
      "Time:48.0s\n",
      "Val Loss:0.222651 Accuracy:0.1854 \n",
      "Time:7.3s\n",
      "\n",
      "Epoch 39/39\n",
      "----------\n",
      "Train Loss:0.224066 Accuracy:0.1412 \n",
      "Time:47.5s\n",
      "Val Loss:0.223007 Accuracy:0.1801 \n",
      "Time:7.2s\n",
      "\n",
      "Training complete in 36m 26s\n",
      "Best val Acc: 0.1861\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
