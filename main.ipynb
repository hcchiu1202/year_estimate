{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VasQZtkW3Mek"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "AdvL_oIylKeT",
    "outputId": "44662ee3-6fb5-4813-8264-97e68e14c4d4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "import cv2\n",
    "import collections\n",
    "import time\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations import pytorch as AT\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnet_pytorch.utils import Conv2dStaticSamePadding\n",
    "\n",
    "from catalyst.data import Augmentor\n",
    "from catalyst.dl import utils\n",
    "from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.dl.callbacks import AccuracyCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback, MixupCallback\n",
    "from catalyst.dl.core.callback import MetricCallback\n",
    "from catalyst.utils import set_global_seed, prepare_cudnn\n",
    "from catalyst.dl import utils\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.contrib.criterion import FocalLossMultiClass\n",
    "from catalyst.contrib.schedulers import OneCycleLRWithWarmup\n",
    "\n",
    "from datetime import datetime\n",
    "from torchsummary import summary\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "SEED = 255  # FF\n",
    "set_global_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vOSAhuk54mcg"
   },
   "source": [
    "## Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_W4AUEGIv8sE"
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "train = pd.read_csv('./train_labels1979to1980.csv', header=None, names=[\"id\", \"label\"])\n",
    "train['label'] = train['label'] - 1980\n",
    "time_run = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "logdir = \"./results/\"+ time_run\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "num_class = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Vgtmdcgr3RuV",
    "outputId": "2b9bc0cf-533f-4402-8c6d-f9edd150e7c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0001.png</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0002.png</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0003.png</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0004.png</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0005.png</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  label\n",
       "0  train_0001.png     32\n",
       "1  train_0002.png     23\n",
       "2  train_0003.png     14\n",
       "3  train_0004.png     34\n",
       "4  train_0005.png     23"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lx88oZtc3ZiS",
    "outputId": "98d5c6ac-3cec-49e1-d7c6-632533374fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6686 images in train dataset\n",
      "There are 1671 images in test dataset\n"
     ]
    }
   ],
   "source": [
    "n_train = len(os.listdir(f'{path}/train_images'))\n",
    "n_test = len(os.listdir(f'{path}/test_images'))\n",
    "print(f'There are {n_train} images in train dataset')\n",
    "print(f'There are {n_test} images in test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "7r5ETIF33UVO",
    "outputId": "41f87b9c-25a7-4068-e478-3d3b3e3e5d5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x179147bfef0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['label'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeT9dRoB7ifd"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7GCqGl3xg_B"
   },
   "outputs": [],
   "source": [
    "class FFDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame = None, datatype: str = 'train',\n",
    "                 transforms=albu.Compose([albu.HorizontalFlip(), AT.ToTensor()]), ):\n",
    "\n",
    "        self.df = df\n",
    "        self.data = df['id']\n",
    "        self.label = df['label']\n",
    "        if datatype != 'test':\n",
    "            self.data_folder = f\"{path}/train_images\"\n",
    "        else:\n",
    "            self.data_folder = f\"{path}/test_images\"\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data[idx]\n",
    "        image_path = os.path.join(self.data_folder, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        augmented = self.transforms(image=img)\n",
    "        org_img = augmented['image']\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        ''' fourier transform input data\n",
    "        f = np.fft.fft2(org_img)\n",
    "        fr = f.real\n",
    "        fr = torch.from_numpy(fr).float()\n",
    "        fi = f.imag\n",
    "        fi = torch.from_numpy(fi).float()\n",
    "        img = torch.cat((org_img, fr, fi), 0)\n",
    "        \n",
    "        return img, label\n",
    "        '''\n",
    "        return org_img, label\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    activation_fn = get_activation_fn(activation)\\n    outputs = activation_fn(outputs)\\n\\n    if threshold:\\n        outputs = (outputs > threshold).long()\\n\\n    # multi-label classification\\n    if len(targets.shape) > 1 and targets.size(1) > 1:\\n        res = (targets.long() == outputs.long()).sum().float() / np.prod(\\n            targets.shape)\\n        return [res]\\n\\n    max_k = max(topk)\\n    batch_size = targets.size(0)\\n\\n    if len(outputs.shape) == 1 or outputs.shape[1] == 1:\\n        pred = outputs.t()\\n    else:\\n        _, pred = outputs.topk(max_k, 1, True, True)\\n        pred = pred.t()\\n    correct = pred.eq(targets.long().view(1, -1).expand_as(pred))\\n\\n    res = []\\n    for k in topk:\\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\\n        res.append(correct_k.mul_(100.0 / batch_size))\\n    return res\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_fn(output, target):\n",
    "    '''\n",
    "    -targets is a tensor: batch_size\n",
    "    -outputs is a tensor: batch_size x num_classes\n",
    "    torch.Size([32, 39])\n",
    "target--- tensor([10, 24, 14, 24, 29, 33,  8, 32, 15,  8, 17, 18, 14, 38, 19, 11, 10, 14,\n",
    "        30, 18, 14, 24, 10, 36, 10, 24, 28, 11, 38, 13, 26, 26],\n",
    "       device='cuda:0')\n",
    "torch.Size([32])\n",
    "    \n",
    "    '''\n",
    "    _, idx = torch.max(output, 1)\n",
    "    \n",
    "    \n",
    "    print(\"output---\", output)\n",
    "    print(output.shape)\n",
    "    print(\"target---\", target)\n",
    "    print(target.shape)\n",
    "#    y_pred = tf.math.argmax(y_pred, axis=-1, output_type=\"int32\")\n",
    "#    return tf.cast(tf.less_equal(tf.math.abs(y_true - y_pred), 1), \"float32\")\n",
    "    score = 1\n",
    "    return score\n",
    "\n",
    "'''\n",
    "    activation_fn = get_activation_fn(activation)\n",
    "    outputs = activation_fn(outputs)\n",
    "\n",
    "    if threshold:\n",
    "        outputs = (outputs > threshold).long()\n",
    "\n",
    "    # multi-label classification\n",
    "    if len(targets.shape) > 1 and targets.size(1) > 1:\n",
    "        res = (targets.long() == outputs.long()).sum().float() / np.prod(\n",
    "            targets.shape)\n",
    "        return [res]\n",
    "\n",
    "    max_k = max(topk)\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    if len(outputs.shape) == 1 or outputs.shape[1] == 1:\n",
    "        pred = outputs.t()\n",
    "    else:\n",
    "        _, pred = outputs.topk(max_k, 1, True, True)\n",
    "        pred = pred.t()\n",
    "    correct = pred.eq(targets.long().view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oY_We83-w59a"
   },
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "# train用のデータ拡張\n",
    "data_transforms = albu.Compose([\n",
    "    albu.Resize(img_height, img_width),\n",
    "    albu.HorizontalFlip(p=0.5),\n",
    "    albu.VerticalFlip(p=0.5),\n",
    "    albu.RandomBrightnessContrast(p=0.3),\n",
    "    albu.RandomGamma(gamma_limit=(85, 115), p=0.3),\n",
    "    albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.10, rotate_limit=45, p=0.5),\n",
    "    albu.GaussNoise(var_limit=(10.0, 50.0), mean=0, p=0.5),   # white noise shouuld be a useful data aug\n",
    "    albu.Normalize(),\n",
    "    AT.ToTensor()\n",
    "])\n",
    "\n",
    "# test用のデータ拡張\n",
    "data_transforms_test = albu.Compose([\n",
    "    albu.Resize(img_height, img_width),\n",
    "    albu.Normalize(),\n",
    "    AT.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "r3nCkXC7w9Uz",
    "outputId": "060c7e8d-7199-4a77-daad-fadbea58a5e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silas\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 学習データを訓練用と検証用に分割\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=SEED)\n",
    "train_index, test_index = skf.split(train['id'], train['label']).__next__()\n",
    "\n",
    "train_df = train.iloc[train_index].reset_index(drop=True)\n",
    "valid_df = train.iloc[test_index].reset_index(drop=True)\n",
    "\n",
    "#Oversampling using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(train_index.reshape(-1, 1), train_df['label'].to_list()) #Resample and expand the train_index\n",
    "train_df_res = train.iloc[X_res.reshape(-1,)].reset_index(drop=True)\n",
    "\n",
    "train_dataset = FFDataset(df=train_df_res, datatype='train', transforms=data_transforms)\n",
    "valid_dataset = FFDataset(df=valid_df, datatype='valid', transforms=data_transforms_test)\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "loaders = collections.OrderedDict()\n",
    "loaders[\"train\"] = train_loader\n",
    "loaders[\"valid\"] = valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuybi7t97bn1"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IuHKrRfsy41Y",
    "outputId": "1a955d67-f868-4154-f3de-17416b7a68c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "#model = Resnet(num_class)\n",
    "#model = CustomEfficientNet(num_classes=num_class, in_chan=9)\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=num_class, in_channels=3)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=3, min_lr=1e-6, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cxiZcF42igh"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "foLStR9zvur9",
    "outputId": "a8d40fca-7381-48a3-a0c2-bee80cf2c14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./year_estimate/results/20200102_224826\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1/2 * Epoch (train):   0% 0/451 [00:00<?, ?it/s]output--- tensor([[-0.1428, -0.1744,  0.1557,  ...,  0.1654,  0.1323,  0.2289],\n",
      "        [-0.0893, -0.0691, -0.0325,  ...,  0.0191, -0.0731, -0.1531],\n",
      "        [ 0.1903, -0.2082, -0.0559,  ...,  0.0234, -0.0843, -0.0803],\n",
      "        ...,\n",
      "        [-0.2532, -0.3687,  0.0598,  ..., -0.1315,  0.0184,  0.0807],\n",
      "        [ 0.0871,  0.0726,  0.2450,  ...,  0.0029,  0.1955, -0.3520],\n",
      "        [ 0.0135,  0.3872,  0.1364,  ...,  0.2472, -0.1437,  0.1228]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([32, 39])\n",
      "target--- tensor([10, 24, 14, 24, 29, 33,  8, 32, 15,  8, 17, 18, 14, 38, 19, 11, 10, 14,\n",
      "        30, 18, 14, 24, 10, 36, 10, 24, 28, 11, 38, 13, 26, 26],\n",
      "       device='cuda:0')\n",
      "torch.Size([32])\n",
      "\n",
      "\n",
      "1/2 * Epoch (train):   0% 0/451 [00:00<?, ?it/s, accuracy01=3.125, accuracy03=3.125, loss=3.711, score=1.000]\n",
      "\n",
      "1/2 * Epoch (train):   0% 1/451 [00:00<05:01,  1.49it/s, accuracy01=3.125, accuracy03=3.125, loss=3.711, score=1.000]output--- tensor([[-0.1644, -0.2164,  0.2966,  ...,  0.1397, -0.1498, -0.0266],\n",
      "        [-0.1911, -0.5666, -0.2505,  ..., -0.2154, -0.4728,  0.0476],\n",
      "        [ 0.3039,  0.0914, -0.1520,  ...,  0.0213, -0.3835, -0.0768],\n",
      "        ...,\n",
      "        [ 0.2067, -0.3093, -0.2664,  ..., -0.1981, -0.4057, -0.1556],\n",
      "        [ 0.1903,  0.0040, -0.0406,  ...,  0.0883,  0.2006,  0.1479],\n",
      "        [-0.4032, -0.4313, -0.1666,  ..., -0.0630, -0.1449, -0.0370]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([32, 39])\n",
      "target--- tensor([22, 18, 10, 19, 12, 32,  6, 15, 11, 15, 21, 12,  4, 38, 18, 15, 28, 18,\n",
      "        18,  4, 30, 31, 12, 22, 33, 36, 24, 15, 32, 16, 14,  4],\n",
      "       device='cuda:0')\n",
      "torch.Size([32])\n",
      "\n",
      "\n",
      "1/2 * Epoch (train):   0% 1/451 [00:01<05:01,  1.49it/s, accuracy01=9.375, accuracy03=21.875, loss=3.584, score=1.000]\n",
      "\n",
      "1/2 * Epoch (train):   0% 2/451 [00:01<05:00,  1.49it/s, accuracy01=9.375, accuracy03=21.875, loss=3.584, score=1.000]output--- tensor([[-0.4680, -0.5351, -0.5438,  ..., -0.0499,  0.0404,  0.1452],\n",
      "        [-0.1734, -0.8696, -0.2037,  ...,  0.0129, -0.4545,  0.2054],\n",
      "        [-0.3757, -0.0630, -0.2366,  ...,  0.3381, -0.0992,  0.6071],\n",
      "        ...,\n",
      "        [ 0.0520, -0.2077, -0.2749,  ..., -0.0673, -0.1491, -0.1985],\n",
      "        [-0.7777, -0.7478, -0.1149,  ..., -0.0226, -0.3973,  0.0433],\n",
      "        [-0.7302, -0.4033, -0.5830,  ..., -0.1343, -0.7676, -0.1456]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([32, 39])\n",
      "target--- tensor([22, 32, 33, 35, 16, 15, 10, 36, 21, 12, 20, 14, 18, 14, 20, 32, 33, 18,\n",
      "        38,  8,  8, 13,  8, 11, 38, 13, 16, 17,  8,  7, 18, 10],\n",
      "       device='cuda:0')\n",
      "torch.Size([32])\n",
      "\n",
      "\n",
      "1/2 * Epoch (train):   0% 2/451 [00:01<05:00,  1.49it/s, accuracy01=3.125, accuracy03=12.500, loss=3.605, score=1.000]\n",
      "\n",
      "1/2 * Epoch (train):   1% 3/451 [00:01<04:58,  1.50it/s, accuracy01=3.125, accuracy03=12.500, loss=3.605, score=1.000]output--- tensor([[-0.2269, -0.5416, -0.4208,  ..., -0.3719, -0.3528,  0.0701],\n",
      "        [-0.9490, -0.9549, -1.0894,  ..., -0.3218, -1.2342,  0.0376],\n",
      "        [-0.7197, -1.4176, -0.9154,  ..., -0.5348, -1.2284,  0.6505],\n",
      "        ...,\n",
      "        [-0.4216, -0.4256, -0.1154,  ..., -0.1690, -0.2297,  0.0850],\n",
      "        [-0.5167, -0.6728, -0.7700,  ..., -0.2793, -0.7442,  0.1616],\n",
      "        [ 0.0239, -0.0906, -0.0577,  ...,  0.1714,  0.2497, -0.2769]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([32, 39])\n",
      "target--- tensor([11, 20, 13,  6, 18, 36, 10,  6, 18, 16, 32, 20, 11, 12, 24, 14, 24, 19,\n",
      "        27,  0,  7, 30,  7,  6, 10, 32, 25, 13,  8, 15, 20, 17],\n",
      "       device='cuda:0')\n",
      "torch.Size([32])\n",
      "\n",
      "\n",
      "1/2 * Epoch (train):   1% 3/451 [00:02<04:58,  1.50it/s, accuracy01=6.250, accuracy03=31.250, loss=3.560, score=1.000]\n",
      "\n",
      "1/2 * Epoch (train):   1% 4/451 [00:02<04:50,  1.54it/s, accuracy01=6.250, accuracy03=31.250, loss=3.560, score=1.000]output--- tensor([[-1.0546e+00, -5.7050e-01, -8.5506e-01,  ..., -3.1031e-01,\n",
      "         -6.3403e-01, -2.1865e-01],\n",
      "        [-9.1357e-01, -6.9105e-01, -3.9628e-01,  ..., -2.3614e-02,\n",
      "         -4.6807e-01,  1.5189e-01],\n",
      "        [-6.2787e-01, -6.3118e-01, -8.0410e-01,  ..., -3.3267e-01,\n",
      "         -4.1533e-01, -3.8416e-02],\n",
      "        ...,\n",
      "        [-2.1415e-01, -4.7326e-01, -3.9379e-01,  ..., -1.3490e-01,\n",
      "         -4.2890e-01,  1.5994e-01],\n",
      "        [ 1.0426e-01, -1.3623e-02,  1.5468e-01,  ..., -1.3813e-01,\n",
      "         -1.7480e-01, -5.6529e-04],\n",
      "        [-2.5488e-01, -3.3973e-01, -4.9328e-01,  ...,  6.6319e-02,\n",
      "         -6.7016e-01, -3.4867e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "torch.Size([32, 39])\n",
      "target--- tensor([15, 24, 19,  9, 13, 24, 21, 12,  9, 24, 36, 27, 10, 20,  5, 19, 33, 10,\n",
      "        17, 24, 30, 24, 24, 24,  4, 16, 26, 32, 15, 11, 10, 16],\n",
      "       device='cuda:0')\n",
      "torch.Size([32])\n",
      "\n",
      "\n",
      "1/2 * Epoch (train):   1% 4/451 [00:03<04:50,  1.54it/s, accuracy01=6.250, accuracy03=21.875, loss=3.511, score=1.000]\n",
      "\n",
      "                                                                                                             \n",
      "                                                \n",
      "\n",
      "Early exiting\n",
      "3/80 * Epoch (train):  75% 339/451 [29:41:49<01:09,  1.62it/s, accuracy01=46.875, accuracy03=75.000, loss=1.759]\n",
      "1/2 * Epoch (train):   0% 0/451 [13:53<?, ?it/s]\n",
      "\n",
      "1/2 * Epoch (train):   1% 5/451 [00:03<04:51,  1.53it/s, accuracy01=6.250, accuracy03=21.875, loss=3.511, score=1.000]"
     ]
    }
   ],
   "source": [
    "print(logdir)\n",
    "# model runner\n",
    "num_epochs = 2\n",
    "runner = SupervisedRunner()\n",
    "\n",
    "#resume_dir=None\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    callbacks=[\n",
    "               AccuracyCallback(num_classes=num_class, accuracy_args=[1,3]),\n",
    "               # EarlyStoppingCallback(patience=5, min_delta=0.001),\n",
    "               # MetricCallback(prefix='score', metric_fn=score_fn),     #score_fn not yet finished\n",
    "               CheckpointCallback(save_n_best=num_epochs, resume_dir=None),\n",
    "               ],\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    main_metric='accuracy01',\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKPSz2lP2clm"
   },
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dk9XsdVy5g1S"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv', header=None, names=[\"id\", \"label\"])\n",
    "\n",
    "test_dataset = FFDataset(df=submission, datatype='test', transforms=data_transforms_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "G72h3nhTxRjZ",
    "outputId": "f295c756-8736-44d4-fd12-53bdd89a973d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint ./year_estimate/results/20191231_164819/checkpoints/53.pth\n",
      "loaded checkpoint ./year_estimate/results/20191231_164819/checkpoints/53.pth (epoch 53)\n",
      "1/1 * Epoch (infer): 100% 53/53 [00:09<00:00,  5.88it/s]\n",
      "Top best models:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = runner.predict_loader(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    resume=f\"{logdir}/checkpoints/53.pth\",\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "# print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaAjI4I264cY"
   },
   "outputs": [],
   "source": [
    "class_names = sorted(list(train['label'].unique()))\n",
    "pred_list = []\n",
    "for i in range(n_test):\n",
    "    probabilities = torch.softmax(torch.from_numpy(predictions[i]), dim=0)\n",
    "    label = probabilities.argmax().item()\n",
    "    pred_list.append(class_names[label] + 1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O81Km3fcxX7p"
   },
   "outputs": [],
   "source": [
    "submission['label'] = pred_list\n",
    "submission.to_csv(f\"{logdir}/submission.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ff_demo_cls.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
